{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMaptPKQ1Lhan2daaheNhL9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DETT95FYLrAw"},"outputs":[],"source":["# Mount google drive\n","from google.colab import drive\n","!mkdir /gdrive\n","drive.mount('/gdrive')"]},{"cell_type":"code","source":["import os"],"metadata":{"id":"fgzLdpB2MXDi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2, numpy as np, pathlib, concurrent.futures as cf"],"metadata":{"id":"vwn3Q1N3VEHv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["orange_temp = os.path.join('/gdrive/MyDrive/object_detection_company', 'orange_temp.jpg')\n","apple_temp = os.path.join('/gdrive/MyDrive/object_detection_company', 'apple_temp.jpg')\n","\n","input_dir = os.path.join('/gdrive/MyDrive/object_detection_company', 'input')\n","output_dir = os.path.join('/gdrive/MyDrive/object_detection_company', 'output')"],"metadata":{"id":"cXwwou8jMNyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","cv2_imshow(cv2.imread(orange_temp))\n","cv2_imshow(cv2.imread(apple_temp))"],"metadata":{"id":"ykdPsTHDM26T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","def frames_from_camera():\n","    for img_path in Path(input_dir).glob(\"*.jpg\"):\n","        yield cv2.imread(str(img_path))"],"metadata":{"id":"J-J41JxiPC_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for img_path in Path(input_dir).glob(\"*.jpg\"):\n","  print(str(img_path))"],"metadata":{"id":"4I8fQTjPSQxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- ① テンプレート準備（起動時に一度だけ） ---\n","tmpl_paths = [orange_temp, apple_temp]\n","#orb = cv2.ORB_create(nfeatures=1200)\n","sift = cv2.SIFT_create()\n","tmpl_db = []     # [(kp, des, corners4, label), ...]\n","\n","for p in tmpl_paths:\n","    img = cv2.imread(p, cv2.IMREAD_GRAYSCALE)\n","    #kp, des = orb.detectAndCompute(img, None)\n","    kp, des = sift.detectAndCompute(img, None)\n","    h, w = img.shape\n","    corners = np.float32([[0,0],[w,0],[w,h],[0,h]]).reshape(-1,1,2)\n","    tmpl_db.append((kp, des, corners, pathlib.Path(p).stem))\n","\n","#bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n","# SIFT 用 BFMatcher（float型）には NORM_L2 を使う\n","bf = cv2.BFMatcher(cv2.NORM_L2)"],"metadata":{"id":"spe-NGf1VGyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- ② 検出ループ ---\n","def detect_and_crop(frame_bgr):\n","    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n","    kp_frame, des_frame = sift.detectAndCompute(gray, None)\n","    if des_frame is None: return []\n","\n","    crops = []\n","    for kp_tmpl, des_tmpl, corners, label in tmpl_db:\n","        matches = bf.knnMatch(des_tmpl, des_frame, k=2)\n","        good = [m for m,n in matches if m.distance < 0.95*n.distance]\n","\n","        if len(good) < 10:             # inlier閾値調整\n","            continue\n","\n","        src_pts = np.float32([kp_tmpl[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n","        dst_pts = np.float32([kp_frame[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n","\n","        if len(src_pts) < 4:\n","            continue\n","\n","        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 3.0)\n","        if H is None or mask is None or mask.sum() < 10:\n","            continue\n","\n","        inliers = mask.sum()\n","        if inliers < 5: continue\n","\n","        proj = cv2.perspectiveTransform(corners, H)\n","        x, y, w, h = cv2.boundingRect(proj)\n","        pad = int(0.05 * max(w, h))\n","        crop = frame_bgr[max(0, y - pad):y + h + pad, max(0, x - pad):x + w + pad]\n","\n","        crops.append((crop, label, inliers))\n","    return crops\n","\n","# --- ③ 並列保存例 ---\n","executor = cf.ThreadPoolExecutor()\n","\n","for frame_id, frame in enumerate(frames_from_camera()):\n","    crops = detect_and_crop(frame)\n","    print(f\"frame {frame_id}: {len(crops)} objects found\")  # ← 追加してみて\n","    for i,(crop,label,score) in enumerate(detect_and_crop(frame)):\n","        print(i)\n","        executor.submit(cv2.imwrite,\n","                        os.path.join(output_dir, f\"{label}_{frame_id}_{i}_{score}.png\"),\n","                        crop)\n"],"metadata":{"id":"R5pU-VbwMMLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- ② 画像に特徴点を描画する関数 ---\n","def detect_and_annotate(frame_bgr):\n","    gray = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2GRAY)\n","    kp_frame, des_frame = sift.detectAndCompute(gray, None)\n","    if des_frame is None:\n","        return []                                      # 何も描けない\n","\n","    annotated_imgs = []                                # [(annotated_img, label, inliers), …]\n","\n","    # テンプレートごとにマッチング\n","    for kp_tmpl, des_tmpl, tmpl_corners, label in tmpl_db:\n","        matches = bf.knnMatch(des_tmpl, des_frame, k=2)\n","        good = [m for m, n in matches if m.distance < 0.95 * n.distance]\n","        if len(good) < 10:\n","            continue\n","\n","        src_pts = np.float32([kp_tmpl[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n","        dst_pts = np.float32([kp_frame[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n","        if len(src_pts) < 4:\n","            continue\n","\n","        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 3.0)\n","        if H is None or mask is None or mask.sum() < 10:\n","            continue\n","\n","        inliers = int(mask.sum())\n","\n","        # ---------- 描画 ----------\n","        canvas = frame_bgr.copy()\n","\n","        # 1) 対応キーポイント（入力側）を緑で描画\n","        matched_kp = [kp_frame[m.trainIdx] for m in good]\n","        cv2.drawKeypoints(canvas, matched_kp, canvas,\n","                          color=(0,255,0),\n","                          flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","        # 2) テンプレート枠を射影して多角形で描画（赤）\n","        proj = cv2.perspectiveTransform(tmpl_corners, H)\n","        cv2.polylines(canvas, [np.int32(proj)], True, (0,0,255), 2, cv2.LINE_AA)\n","\n","        # 3) ラベル＆インライヤ数を表示\n","        x, y = np.int32(proj[0,0])\n","        cv2.putText(canvas, f\"{label}:{inliers}\", (x, y-10),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2, cv2.LINE_AA)\n","\n","        annotated_imgs.append((canvas, label, inliers))\n","    return annotated_imgs\n","\n","# --- ③ 並列保存ループ ---\n","executor = cf.ThreadPoolExecutor()\n","\n","for frame_id, frame in enumerate(frames_from_camera()):\n","    anns = detect_and_annotate(frame)\n","    print(f\"frame {frame_id}: {len(anns)} matches\")\n","\n","    for i, (ann_img, label, score) in enumerate(anns):\n","        fname = os.path.join(output_dir, f\"{label}_{frame_id}_{i}_{score}.png\")\n","        executor.submit(cv2.imwrite, fname, ann_img)\n","\n","executor.shutdown(wait=True)"],"metadata":{"id":"VUYOR2b4engo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 閾値の設定\n","threshold = 200\n","orange=cv2.imread(orange_temp, cv2.IMREAD_GRAYSCALE)\n","# 二値化(閾値100を超えた画素を255にする。)\n","ret, img_thresh = cv2.threshold(orange, threshold, 255, cv2.THRESH_BINARY)\n","kernel = np.ones((5,5),np.uint8)\n","opening = cv2.morphologyEx(img_thresh, cv2.MORPH_OPEN, kernel)\n","cv2_imshow(opening)"],"metadata":{"id":"blS-QlvtJY8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","\n","# 画像の読み込み（グレースケールで）\n","img = cv2.imread(orange_temp, cv2.IMREAD_GRAYSCALE)\n","\n","# ORB 特徴点検出\n","orb = cv2.ORB_create(nfeatures=500)\n","kp, des = orb.detectAndCompute(img, None)\n","\n","# SIFT 特徴点検出\n","sift = cv2.SIFT_create()\n","kp, des = sift.detectAndCompute(opening, None)\n","\n","# 特徴点を描画（色は緑）\n","img_kp = cv2.drawKeypoints(img, kp, None, color=(0,255,0),\n","                           flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","# 表示（または保存）\n","cv2_imshow(img_kp)"],"metadata":{"id":"wFgwiDAAXGpM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","# --- 1. 画像読み込み（グレースケール） ---\n","img1 = cv2.imread(orange_temp, cv2.IMREAD_GRAYSCALE)  # テンプレート画像\n","img2 = cv2.imread(os.path.join(input_dir, 'orange_58.jpg'), cv2.IMREAD_GRAYSCALE)  # 入力画像\n","\n","# --- 2. 特徴点抽出（SIFT） ---\n","sift = cv2.SIFT_create()\n","kp1, des1 = sift.detectAndCompute(opening, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","# --- 3. マッチング（Brute-Force + L2距離） ---\n","bf = cv2.BFMatcher(cv2.NORM_L2)\n","matches = bf.knnMatch(des1, des2, k=2)\n","\n","# --- 4. Ratio Test（Lowe’s ratio）で良いマッチだけ選ぶ ---\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.95 * n.distance:\n","        good.append(m)\n","\n","# --- 5. マッチング結果の描画 ---\n","img_matches = cv2.drawMatches(\n","    img1, kp1,\n","    img2, kp2,\n","    good, None,\n","    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS\n",")\n","\n","# --- 6. 表示または保存 ---\n","cv2_imshow(img_matches)\n"],"metadata":{"id":"rP7ihv6GcTSH"},"execution_count":null,"outputs":[]}]}